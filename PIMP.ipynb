{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b3a80d",
   "metadata": {},
   "source": [
    "\n",
    "**Permutation Feature Importance (PFI):**\n",
    "\n",
    "The idea behind PFI is to evaluate the importance of a feature by measuring the increase in the model's prediction error after permuting the feature. This is done to \"destroy\" the structure of the feature while keeping the marginal distribution $ P(x_j) $ unchanged. The steps are as follows:\n",
    "\n",
    "1. Measure the baseline error of the model using the test set without permuting any features.\n",
    "2. For the feature of interest, permute its values across the observations in the test set, thus creating a new dataset where the association between the feature and the outcome is broken.\n",
    "3. Measure the error of the model on this new dataset.\n",
    "4. The importance of the feature is then the difference between the error with the permuted feature and the baseline error.\n",
    "5. Repeat this process multiple times and average the differences to get the Permutation Feature Importance score for that feature.\n",
    "\n",
    "**Testing Importance using Permutations (PIMP):**\n",
    "\n",
    "PIMP is a method to test the statistical significance of the Permutation Feature Importance scores. This is done by creating a null distribution of feature importance scores under the hypothesis that the feature is not informative (i.e., it has no relationship with the response variable). The steps are:\n",
    "\n",
    "1. Permute the response variable $ y $ and retrain the model with the permuted $ y $ and original features $ X $ to compute feature importance under the null hypothesis $ H_0 $. This is repeated for a number of repetitions to create a distribution of importance scores under $ H_0 $.\n",
    "2. Train the model with the original $ X $ and $ y $ to compute the actual feature importance.\n",
    "3. For each feature, fit a probability distribution to the null importance scores (can be Gaussian, lognormal, gamma, or non-parametric).\n",
    "4. Compute the actual feature importance for the model with the original $ y $ (under $ H_1 $, the alternative hypothesis).\n",
    "5. Retrieve the p-value of the actual feature importance based on the fitted null distribution.\n",
    "\n",
    "The PIMP method allows one to assess whether the observed importance is significantly different from what would be expected by random chance, thus providing a statistical significance test for feature importance scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import norm, gamma, lognorm\n",
    "\n",
    "# Assume data_original is a pandas DataFrame with the last column being the binary target\n",
    "X = data_original.iloc[:, :-1]  # Features\n",
    "y = data_original.iloc[:, -1]   # Labels (binary)\n",
    "\n",
    "# Function to compute permutation importance for a single feature\n",
    "def permutation_importance(model, X, y, feature, n_repeats=30):\n",
    "    baseline_accuracy = accuracy_score(y, model.predict(X))\n",
    "    scores = np.zeros(n_repeats)\n",
    "    for n in range(n_repeats):\n",
    "        X_permuted = X.copy()\n",
    "        X_permuted[feature] = shuffle(X_permuted[feature].values, random_state=None)\n",
    "        permuted_accuracy = accuracy_score(y, model.predict(X_permuted))\n",
    "        scores[n] = baseline_accuracy - permuted_accuracy\n",
    "    return scores\n",
    "\n",
    "# Calculate the actual importances for each feature with unpermuted y\n",
    "actual_importances = {feature: permutation_importance(trained_model, X, y, feature) for feature in X.columns}\n",
    "\n",
    "# actual_importances[feature] contains the PFI scores for each feature\n",
    "\n",
    "# Initialize null importances\n",
    "null_importances = {column: [] for column in X.columns}\n",
    "\n",
    "n_repetitions = 100  # Number of repetitions for null distribution\n",
    "for _ in range(n_repetitions):\n",
    "    y_permuted = shuffle(y, random_state=None)\n",
    "    null_model = trained_model.fit(X, y_permuted)  # Retrain model with permuted y\n",
    "    for column in X.columns:\n",
    "        null_importance = permutation_importance(null_model, X, y_permuted, n_repeats=1)\n",
    "        null_importances[column].extend(null_importance)\n",
    "\n",
    "# Assuming a normal distribution for the null importances\n",
    "p_values = {}\n",
    "for column in X.columns:\n",
    "    # Fit a normal distribution to the null importances\n",
    "    mu, std = norm.fit(null_importances[column])\n",
    "    # Compute the p-value for the actual importance\n",
    "    p_value = 1 - norm.cdf(actual_importances[X.columns.get_loc(column)], mu, std)\n",
    "    p_values[column] = p_value\n",
    "\n",
    "# Print p-values for each feature\n",
    "print(p_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
